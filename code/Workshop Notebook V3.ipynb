{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed2e768-dc1c-46b6-a70f-fa4345ecb0e8",
   "metadata": {
    "jupyter": {
     "source_hidden": false
    }
   },
   "source": [
    "<h1 align=\"center\">UW CNC Fall Hackathon </h1>  \n",
    "<h3 align=\"center\"> Dec 4, 2024 </h3>   \n",
    "<h3 align=\"center\"> mapping mesoscale connectivity between the frontal cortex and thalamus</h3> \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9450874e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "**Overview:** In this notebook, we will analyze thalamic projections to frontal cortex using a 3D light sheet microscopy dataset from whole mouse brains. While this tutorial focuses on thalamocortical connectivity, the dataset contains connections between the frontal cortex and other brain regions, which have yet to be thoroughly explored. \n",
    "    \n",
    "**Dataset:**  This dataset was collected using the mesoscale anatomy platform established at the Allen Institute for Neural Dynamics. Brain samples are cleared and imaged on a SmartSPIM lightsheet microscope. Images are stitched and fused into a 3D volume and aligned to the Common Coordinate Framework (CCF), which allows for integration between samples. Candidate cell somas are algorithmically detected and then classified as true detections or non-cells using a trained deep neural network. This yields a collection of cells throughout the brain, each of which are localized within CCF space. The datasets in this tutorial have been QC'd to verify accurate cell detection, but this verification has been primarily performed in thalamus. Care should be taken to verify cell counts in other regions before drawing strong conclusions. \n",
    "    \n",
    "**Experiment:** These experiments are focused on the structure of inputs to frontal cortex. Retrograde viruses were injected across the frontal cortex, eliciting expression of nuclear-localized fluorophores in infected cells. These injections label somas at the site of virus delivery, as well as the somas of neurons with axonal projections to that location. The brains in this dataset received 1-3 injections of viruses expressing spectrally distinct fluorophores, and thus each injection is conceptualized as an independent connectivity mapping experiment. While the majority of these viral injections employed AAVrg-XFPs, other reagents were also used to address potential cellular or axonal density based tropism. The location of each injection site was empirically determined.\n",
    "        \n",
    "    \n",
    "**Goal:** This tutorial will show you how to:  \n",
    "    1. analyze connectivity across brain regions  \n",
    "    2. work with 3D volumetric microscopy data of whole mouse brains \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538e274b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "#### Import packages and load data<br>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f94bd0-8928-4a05-8079-2aa84a3ac300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# general imports \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "531bb4ba-851d-45a7-8a5e-a0eeab22b67c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specific imports and brain atlas initialization \n",
    "\n",
    "from load_data import load_data\n",
    "import brainglobe_atlasapi as atlasapi\n",
    "from brainglobe_atlasapi import BrainGlobeAtlas\n",
    "atlasapi.config.write_config_value('brainglobe_dir', '/data/.brainglobe') # points to allen mouse atlases pre-loaded in data folder \n",
    "atlas = BrainGlobeAtlas('allen_mouse_25um', \n",
    "                        check_latest = False) # load CCF mouse brain atlas, 25um resolution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46612880",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "#### Load data for a single brain \n",
    "      \n",
    "The load_data object class is a wrapper for pulling relevant lightsheet data and data products from the /data folders for a given mouse ID. Here, we'll load the data for a single mouse_ID.  \n",
    "\n",
    "You'll see which channels passed through each stage of processing: \n",
    "raw image channels > cell detection model applied > transformation to CCF space). The 639 channel is used for imaging autofluorescent tissue (background), so there should not be detected cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "797a2cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class load_data in module load_data:\n",
      "\n",
      "class load_data(builtins.object)\n",
      " |  load_data(sample, level=3)\n",
      " |  \n",
      " |  A class to load, process, and analyze whole-brain volumetric imaging data for a specified mouse ID. \n",
      " |  \n",
      " |  Parameters\n",
      " |  -----------\n",
      " |  sample : int or str \n",
      " |      Mouse ID (e.g., 689305) \n",
      " |  \n",
      " |  level : int, optional \n",
      " |      Resolution level for loading volumetric imaging data. Range: 0 - 4, higher numbers equate to greater downsampling.      \n",
      " |      Default = 3.  \n",
      " |  \n",
      " |  Attributes \n",
      " |  ----------\n",
      " |  baseResolution : list of float\n",
      " |      Base voxel resolution in microns: [1.8, 1.8, 2]\n",
      " |      \n",
      " |  zarrMultiple : dict \n",
      " |      A dictionary mapping Zarr resolution levels to their corresponding compression factors \n",
      " |      \n",
      " |  rootDir : pathlib.Path \n",
      " |      Root directory for the mouse ID data. \n",
      " |      \n",
      " |  channels : list of str \n",
      " |      List of imaging channels (e.g., [\"488\", \"561\"]) in the dataset \n",
      " |      \n",
      " |  chPaths : dict \n",
      " |      Dictionary mapping channel names to their corresponding volumetric data paths. \n",
      " |      \n",
      " |  segPaths : dict \n",
      " |      Dictionary mapping channel names to paths for segmentated cell data. \n",
      " |      \n",
      " |  quantPaths : dict \n",
      " |      Dictionary mapping channel names to paths for CCF-aligned cell count data. \n",
      " |      \n",
      " |  ccfCellsPaths : dict \n",
      " |      Dictionary mapping channel names to paths for CCF-transformed cell coordinate data. \n",
      " |      \n",
      " |  vols : dict \n",
      " |      Dictionary of loaded volumetric imaging data arrays for each channel \n",
      " |      \n",
      " |  Methods \n",
      " |  --------\n",
      " |  getPath(): \n",
      " |      Locates and validates file paths for imaging data, cell segmentations, and CCF quantifications. \n",
      " |      \n",
      " |  setLevel(level, printOutput = True):\n",
      " |      Updates the resolution level and loads the corresponding volumetric imaging data. \n",
      " |      \n",
      " |  getVol():\n",
      " |      Loads the volumetric imaging data for all available channels at the specified resolution level. \n",
      " |  \n",
      " |  orientVol(ch, plane=\"coronal\", returnLabels=False): \n",
      " |      Orients a channel's volumetric data to a specified plane (coronal, sagittal, or transverse). \n",
      " |      \n",
      " |  setColorMaps(base=\"black\", channelColors={}): \n",
      " |      Sets colormaps for visualization\n",
      " |      \n",
      " |  plotSlice(ch=[], plane=\"coronal\", section=[], extent=[], level=3, ticks=True, printOutput=True):\n",
      " |      Plots a single brain slice for the specified channel, plane and resolution level. \n",
      " |      \n",
      " |  getCellsCCFdf(ch): \n",
      " |      Extracts the CCF-transformed coordinates for specified channels and returns as a DataFrame. \n",
      " |      \n",
      " |  getcellcounts(ch): \n",
      " |      Extracts the cell counts by brain region for specified channels and returns as a DataFrame.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, sample, level=3)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  getCellsCCFdf(self, ch: list)\n",
      " |      Retrieves and formats CCF transformed coordinates of segmented cells into a dataframe. \n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ch : list of str \n",
      " |          List of imaging channels to retrieve coordinates from (e.g., [\"488\", \"561\"]). \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      location_df : pd.DataFrame\n",
      " |          Dataframe where each row is a cell and each column is a coordinate: AP (anterior-posterior), DV (dorsal-ventral), or ML (medial-lateral), with an additional \"channel\" column indicating the channel of origin.\n",
      " |  \n",
      " |  getPath(self)\n",
      " |      # Methods\n",
      " |  \n",
      " |  getVol(self)\n",
      " |  \n",
      " |  getcellcounts(self, ch: list)\n",
      " |      Imports the cell_counts_by_region.csv (quantification of detected cells in brain regions) as a dataframe \n",
      " |      \n",
      " |          Parameters\n",
      " |          ----------\n",
      " |          ch : list of str \n",
      " |              List of imaging channels to retrieve coordinates from (e.g., [\"488\", \"561\"]). \n",
      " |      \n",
      " |          Returns\n",
      " |          -------\n",
      " |          cell_counts_df : pd.DataFrame\n",
      " |              DataFrame where each row is a brain region cell count in a given channel\n",
      " |  \n",
      " |  orientVol(self, ch, plane='coronal', returnLabels=False)\n",
      " |  \n",
      " |  plotSlice(self, ch=[], plane='coronal', section=[], extent=[], level=3, ticks=True, printOutput=True)\n",
      " |      Plots a single brain slice from the volumetric data in a specified plane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      ch : str, optional\n",
      " |          Imaging channel to plot (e.g., \"488\", \"561\"). If not specified, defaults to the shortest wavelength available.\n",
      " |          \n",
      " |      plane : str, optional\n",
      " |          Plane in which to view the slice: \"coronal\", \"sagittal\", or \"transverse\". Defaults to \"coronal\".\n",
      " |          \n",
      " |      section : int or float, optional\n",
      " |          Position along the selected plane, in microns, to slice. If not specified, defaults to the midpoint.\n",
      " |          \n",
      " |      extent : list of float, optional\n",
      " |          4-element list defining the [left, right, bottom, top] extent of the plot in microns.\n",
      " |          If not provided, defaults to the entire image field.\n",
      " |          \n",
      " |      level : int, optional\n",
      " |          Downsampling level for the data. Higher levels correspond to more downsampling, for faster plotting. Default is 3.\n",
      " |          \n",
      " |      ticks : bool, optional\n",
      " |          Whether to display x and y axis labels and tick marks. Default is True.\n",
      " |          \n",
      " |      printOutput : bool, optional\n",
      " |          If True, prints information about the section and level being plotted. Default is True.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |          Displays a matplotlib plot of the specified slice.\n",
      " |  \n",
      " |  setColorMaps(self, base='black', channelColors={})\n",
      " |  \n",
      " |  setLevel(self, level, printOutput=True)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  baseResolution = [1.8, 1.8, 2]\n",
      " |  \n",
      " |  zarrMultiple = {0: 1, 1: 2, 2: 4, 3: 8, 4: 16}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f23b1971",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/SmartSPIM_693198_2023-10-02_16-39-10_stitched_2024-01-11_13-20-45/image_tile_fusing/OMEZarr\n",
      "Found the following channels: ['445', '488', '561', '639']\n",
      "Found cell segmentations in the following channels: ['445', '488', '561']\n",
      "Found CCF aligned quantifications in the following channels: ['445', '488', '561']\n"
     ]
    }
   ],
   "source": [
    "mouse_ID = 693198\n",
    "x = load_data(mouse_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd255a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Save the list of channels that passed through cell segmentation and CCF alignment for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8e8d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['445', '488', '561']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channels = list(x.quantPaths.keys())\n",
    "channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439721f4",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "#### Reference metadata \n",
    "      \n",
    "**Task 1:** Using the metadata dataframe, what experimental information do we have about this mouse_ID? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d1431c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/metadata.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metadata_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/scratch/metadata.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m metadata_df[metadata_df\u001b[38;5;241m.\u001b[39msubject_id \u001b[38;5;241m==\u001b[39m mouse_ID]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/metadata.csv'"
     ]
    }
   ],
   "source": [
    "metadata_df = pd.read_csv('/scratch/metadata.csv')\n",
    "\n",
    "metadata_df[metadata_df.subject_id == mouse_ID]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2150fe2b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "#### Data Visualization Tools  \n",
    "    \n",
    "We can look at the imaging data using [neuroglancer](https://github.com/google/neuroglancer), a webGL based tool for visualizing and exploring large volumetric anatomy datasets  \n",
    "    \n",
    "[Neuroglancer interface basics](https://allenswdb.github.io/anatomy/microns-em/em-neuroglancer.html)  \n",
    "    \n",
    "The metadata dataframe has a few neuroglancer links for each subject_id that shows that passed through different processing steps, such as cell segmentation, ccf alignment, and cell counting. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a5f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Stitched Volumetric Imaging Data \n",
    "\n",
    "ch = 561 # pick a channel to look at \n",
    "\n",
    "# filter metadata_df for subject_id and channel of interest, pull ng_link \n",
    "stitched_link = metadata_df[(metadata_df.subject_id == mouse_ID) & (metadata_df.channel == ch)].ng_link.tolist()[0]\n",
    "\n",
    "# renders the link clickable \n",
    "HTML(f'<a href=\"{stitched_link}\" target=\"_blank\">{stitched_link}</a>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c666ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a single channel with cell segmentation applied \n",
    "\n",
    "# filter metadata_df for subject_id and channel of interest, pull ng_link \n",
    "segmentation_link = metadata_df[(metadata_df.subject_id == mouse_ID) & (metadata_df.channel == ch)].ng_channel.tolist()[0]\n",
    "\n",
    "# renders the link clickable \n",
    "HTML(f'<a href=\"{segmentation_link}\" target=\"_blank\">{segmentation_link}</a>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view cell counts in each brain structure \n",
    "\n",
    "cell_segmentation_ccf_link = 'https://aind-neuroglancer-sauujisjxq-uw.a.run.app/#!%7B%22dimensions%22:%7B%22z%22:%5B0.000024999999999999998%2C%22m%22%5D%2C%22y%22:%5B0.000024999999999999998%2C%22m%22%5D%2C%22x%22:%5B0.000024999999999999998%2C%22m%22%5D%2C%22t%22:%5B0.001%2C%22s%22%5D%7D%2C%22position%22:%5B249.75%2C166.5%2C264.5%2C0.5%5D%2C%22crossSectionScale%22:0.5%2C%22projectionScale%22:1024%2C%22layers%22:%5B%7B%22type%22:%22image%22%2C%22source%22:%22zarr://s3://aind-open-data/SmartSPIM_693198_2023-10-02_16-39-10_stitched_2024-01-11_13-20-45/image_atlas_alignment/Ex_561_Em_593/OMEZarr/image.zarr%22%2C%22localDimensions%22:%7B%22c%27%22:%5B1%2C%22%22%5D%7D%2C%22localPosition%22:%5B0.5%5D%2C%22tab%22:%22source%22%2C%22shaderControls%22:%7B%22normalized%22:%7B%22range%22:%5B0%2C500%5D%7D%7D%2C%22name%22:%22image_25_um%22%7D%2C%7B%22type%22:%22annotation%22%2C%22source%22:%22precomputed://s3://aind-open-data/SmartSPIM_693198_2023-10-02_16-39-10_stitched_2024-01-11_13-20-45/image_cell_quantification/Ex_561_Em_593/visualization/cell_points_precomputed%22%2C%22tool%22:%22annotatePoint%22%2C%22tab%22:%22annotations%22%2C%22name%22:%22cell_points%22%7D%2C%7B%22type%22:%22segmentation%22%2C%22source%22:%22precomputed://s3://aind-open-data/SmartSPIM_693198_2023-10-02_16-39-10_stitched_2024-01-11_13-20-45/image_cell_quantification/Ex_561_Em_593/visualization/ccf_cell_precomputed%22%2C%22tab%22:%22source%22%2C%22name%22:%22cell_counting_in_CCF%22%7D%5D%2C%22selectedLayer%22:%7B%22visible%22:true%2C%22layer%22:%22image_25_um%22%7D%2C%22layout%22:%224panel%22%7D'\n",
    "\n",
    "HTML(f'<a href=\"{cell_segmentation_ccf_link}\" target=\"_blank\">{cell_segmentation_ccf_link}</a>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040341f7",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "**Automated Cell Detection**  \n",
    "    \n",
    "With this dataset, we can map which brain regions provide input to the frontal cortex. To do so, we need to find all of the cells labelled by each viral injection, and the locations of those cells in the brain. Manually annotating these cells is quite laborious, especially at the whole brain scale. To facilitate quantitative insights from these experiments, cells were automatically detected using machine vision models. The rest of this tutorial will show you how to load and analyze the spatial coordinates of these detected cells.  \n",
    "    \n",
    "The `getCellsCCFdf` function loads the spatial coordinates of the detected cells in a given channel. Note that these coordinates are transformed into CCF space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a97c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(x.getCellsCCFdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b38b213",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "lxml not found, please install or use the etree parser.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cellLocs \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetCellsCCFdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchannels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m cellLocs\n",
      "File \u001b[0;32m~/capsule/code/load_data.py:276\u001b[0m, in \u001b[0;36mload_data.getCellsCCFdf\u001b[0;34m(self, ch)\u001b[0m\n\u001b[1;32m    273\u001b[0m         locCells_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m channel \u001b[38;5;129;01min\u001b[39;00m ch:\n\u001b[0;32m--> 276\u001b[0m             locCells \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mccfCellsPaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mchannel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//CellCounter_Marker_File//Marker_Data//Marker_Type//Marker\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# #             since data was reprocessed, coordinates exported in AP, DV, ML order \u001b[39;00m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;66;03m#             locCells = locCells[['MarkerZ', 'MarkerY', 'MarkerX']]  # Rearrange indices to be AP, DV, ML\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m#             locCells = locCells.rename(columns={'MarkerZ': 'AP', 'MarkerY': 'DV', 'MarkerX': 'ML'})  # Rename columns\u001b[39;00m\n\u001b[1;32m    280\u001b[0m             locCells \u001b[38;5;241m=\u001b[39m locCells[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarkerX\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarkerY\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarkerZ\u001b[39m\u001b[38;5;124m'\u001b[39m]]  \u001b[38;5;66;03m# some insurance that data exports in X, Y, Z order \u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/xml.py:1088\u001b[0m, in \u001b[0;36mread_xml\u001b[0;34m(path_or_buffer, xpath, namespaces, elems_only, attrs_only, names, dtype, converters, parse_dates, encoding, parser, stylesheet, iterparse, compression, storage_options)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_or_buffer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    839\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m    840\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    859\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    860\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m    861\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Read XML document into a ``DataFrame`` object.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;124;03m    2  triangle      180    3.0\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1089\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1091\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[43m        \u001b[49m\u001b[43melems_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melems_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1093\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1094\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1096\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconverters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconverters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1097\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1098\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstylesheet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstylesheet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1101\u001b[0m \u001b[43m        \u001b[49m\u001b[43miterparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miterparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/xml.py:805\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(path_or_buffer, xpath, namespaces, elems_only, attrs_only, names, dtype, converters, parse_dates, encoding, parser, stylesheet, iterparse, compression, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m         p \u001b[38;5;241m=\u001b[39m _LxmlFrameParser(\n\u001b[1;32m    789\u001b[0m             path_or_buffer,\n\u001b[1;32m    790\u001b[0m             xpath,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    802\u001b[0m             storage_options,\n\u001b[1;32m    803\u001b[0m         )\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml not found, please install or use the etree parser.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m parser \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124metree\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    808\u001b[0m     p \u001b[38;5;241m=\u001b[39m _EtreeFrameParser(\n\u001b[1;32m    809\u001b[0m         path_or_buffer,\n\u001b[1;32m    810\u001b[0m         xpath,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    822\u001b[0m         storage_options,\n\u001b[1;32m    823\u001b[0m     )\n",
      "\u001b[0;31mImportError\u001b[0m: lxml not found, please install or use the etree parser."
     ]
    }
   ],
   "source": [
    "cellLocs = x.getCellsCCFdf(channels)\n",
    "cellLocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec1819",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "**Task 2:** How many cells were detected in a single channel? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf2f7a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a088779f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "**Plot histograms of the cell locations** \n",
    "\n",
    "Another way to visualize and explore the data is by plotting histograms of the cell coordinates embedded within the anatomical structures. Since this project is focused on mapping thalamocortical connections, we'll take a slice of the brain centered around the thalamus and plot a histogram of the spatial coordinates of the cells targeted in that region. We'll plot in the coronal plane. Using the atlas.get_structure_mask function, we can also overlay the brain structure boundaries to help us identify where the cell targets are. \n",
    "    \n",
    "You can play around with the `plane` and `window` parameters to adjust the location and thickness of the slice we plot or the roiList to outline different brain regions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc0b508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ch = '561' # select a channel \n",
    "plane = 250 # anterior-posterior slice to plot \n",
    "window = 100# slice window bounds \n",
    "roiList = [\"root\", \"TH\"] # brain structures to plot \n",
    "\n",
    "# set figure parameters \n",
    "fig, ax = plt.subplots(figsize=(5, 4))\n",
    "\n",
    "# generate the histogram of cell coordinates\n",
    "planeLocs = cellLocs.loc[(cellLocs['AP'] >= plane - window) & (cellLocs['AP'] <= plane + window), :] # filter cellLocs to coordinates within AP slice bounds\n",
    "\n",
    "# calculate bins for histogram \n",
    "xbins = np.arange(0, atlas.get_structure_mask(\"root\").shape[2], 1) \n",
    "ybins = np.arange(0, atlas.get_structure_mask(\"root\").shape[1], 1)\n",
    "\n",
    "# create histogram of ML, DV coordinates \n",
    "hist, xedges, yedges = np.histogram2d(\n",
    "    planeLocs[planeLocs['channel'] == ch][\"ML\"],\n",
    "    planeLocs[planeLocs['channel'] == ch][\"DV\"],\n",
    "    bins=(xbins, ybins))\n",
    "\n",
    "# overlay the heatmap \n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "heatmap = ax.imshow(\n",
    "    hist.T,  # transpose because imshow expects (rows, cols)\n",
    "    extent=extent,\n",
    "    origin=\"upper\",\n",
    "    cmap=\"viridis\",\n",
    "    alpha=1)\n",
    "\n",
    "# generate contour outlines for brain structures\n",
    "for roi in roiList:\n",
    "    roi_mask = atlas.get_structure_mask(roi) # creates a binary array the size of the brain, mask out brain structures of interest \n",
    "    ax.contour(roi_mask[plane, :, :],\n",
    "        levels=[0.5],\n",
    "        colors=\"white\",\n",
    "        linewidths=1.5,\n",
    "        origin=\"upper\") # plotting features for structure outline \n",
    "\n",
    "# add colorbar and labels \n",
    "cbar = plt.colorbar(heatmap, ax=ax)\n",
    "cbar.set_label(\"Cell Count\")\n",
    "ax.set_title(f\"Histogram of Cell Locations (Channel {ch})\")\n",
    "ax.set_xlabel(\"Medial-Lateral (ML)\")\n",
    "ax.set_ylabel(\"Dorsal-Ventral (DV)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfdc970",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "**Compare cell counts across brain strutures** \n",
    "    \n",
    "We can use the `getcellcounts` function to load a dataframe of the cell counts in each brain structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59817534",
   "metadata": {},
   "source": [
    "| Column    | Description |\n",
    "| -------- | ------- |\n",
    "| ID  | number id of brain structure   |\n",
    "| Acronym | shorthand name of brain structure     |\n",
    "| Name | full name of brain structure     |\n",
    "| Struct_Info    | mid = structure crosses the midline, hemi = structure disconnected across midline  |\n",
    "| Struct_area_um3   | volume of brain structure    |\n",
    "| Left    | left hemisphere cell counts    |\n",
    "| Right    | right hemisphere cell counts   |\n",
    "| Total    | total cell counts   |\n",
    "| Left_Density    | density of cells in left hemisphere of brain structure  |\n",
    "| Right_Density    | density of cells in right hemisphere of brain structure  |\n",
    "| Total_Density    | density of cells in total brain structure   |\n",
    "| channel    | channel name    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a280071",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(x.getcellcounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b06f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_counts_df = x.getcellcounts(channels) # a row for each structure in the CCF ontology (838) \n",
    "cell_counts_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3fd2f4",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "**Construct a Connectivity Matrix** \n",
    "\n",
    "To help us assess the connectivity across brain regions, we can use cell_counts_df to construct a connectivity matrix.  \n",
    "    \n",
    "First, filter the cell counts dataframe to cells within thalamic subregions. Here, we will use the acronym name and look at the leaf node structures (e.g. finest parcellated structures within thalamus). Next, use pivot_table to tabulate the connectivity matrix. Rows = channels, columns = brain structure, values = total cell counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f54f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thalamic subregions of interest (leaf nodes) \n",
    "roiList = [\"MD\", \"PT\", \"IAD\", \"PVT\", \"IMD\", \"CM\", \"PCN\", \"CL\"]\n",
    "\n",
    "# filter the df for cells within the roiList \n",
    "filtered_cell_counts_df = cell_counts_df[cell_counts_df[\"Acronym\"].isin(roiList)] \n",
    "\n",
    "conn_mat = filtered_cell_counts_df.pivot_table(index = \"channel\", \n",
    "                                      columns = \"Acronym\", \n",
    "                                      values = \"Total\")\n",
    "conn_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the connectivity matrix as a heatmap \n",
    "\n",
    "plt.imshow(conn_mat, cmap=\"gray_r\")\n",
    "plt.colorbar(label=\"cell counts\")\n",
    "plt.xticks(ticks=range(len(conn_mat.columns)), labels=conn_mat.columns, rotation=90)\n",
    "plt.yticks(ticks=range(len(conn_mat.index)), labels=conn_mat.index)\n",
    "plt.title(\"Connectivity Matrix\")\n",
    "plt.xlabel(\"Brain Regions\")\n",
    "plt.ylabel(\"Channels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77cf0a",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "\n",
    "**Task 2:** Since each brain structure is variable in size, the total density might be more informative than the total cell counts. Try reconstructing the connectivity matrix and gridded heatmap using total density.    \n",
    "      \n",
    "    \n",
    "**Bonus:** plot as an anatomical heatmap where each brain structure is shaded accordingly with the total density "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd9996f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e137ec5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "**Load multiple datasets**  \n",
    "    \n",
    "A few helper functions to load data for multiple subject_ids and attach metadata information. \n",
    "    \n",
    "`batch_process` will iterate through a list of IDs and output a dataframe of cell locations and a dataframe of cell counts per brain region for each channel within each ID.  \n",
    "    \n",
    "`add_metadata_info` can attach new columns with metadata information by merging the metadata_dataframe with another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa6bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process(id_list): \n",
    "    \"\"\"\n",
    "    Loads data for a list of subject_ids. \n",
    "    \n",
    "    Parameters:\n",
    "        id_list: List of subject_ids \n",
    "\n",
    "    Returns:\n",
    "        cell_locations_df: pandas.DataFrame of cell locations with an additional subject_id column \n",
    "        cell_counts_df: pandas.DataFrame of cell counts in each brain structure with an additional subject_id column \n",
    "    \"\"\"\n",
    "    all_cell_locations = [] \n",
    "    all_cell_counts = [] \n",
    "\n",
    "    for mouse_ID in id_list: # runs load_data through a list of subject_ids \n",
    "        x = load_data(mouse_ID)\n",
    "        channels = list(x.quantPaths.keys())\n",
    "\n",
    "        if len(channels) > 0: # only run if there are processed channels with the subject_id data \n",
    "            cell_locations = x.getCellsCCFdf(channels) # get cell segmentations in CCF \n",
    "            cell_locations = cell_locations.assign(subject_id = mouse_ID) # attach new column w subject_id \n",
    "            all_cell_locations.append(cell_locations) \n",
    "\n",
    "            cell_counts = x.getcellcounts(channels) # get cell counts by brain structure \n",
    "            cell_counts = cell_counts.assign(subject_id = mouse_ID) # attach new column w subject_id \n",
    "            all_cell_counts.append(cell_counts) \n",
    "\n",
    "        else: \n",
    "            pass \n",
    "\n",
    "    cell_locations_df = pd.concat(all_cell_locations) # concatenate dataframes for each subject_id \n",
    "    cell_counts_df = pd.concat(all_cell_counts) \n",
    "    \n",
    "    return cell_locations_df, cell_counts_df \n",
    "\n",
    "\n",
    "def add_metadata_info(data_df, metadata_df, key_columns, additional_columns):\n",
    "    \"\"\"\n",
    "    Cross-references a dataframe with a metadata dataframe based on key columns (subject_id and channel) and adds additional columns from metadata_df. \n",
    "    \n",
    "    Parameters:\n",
    "        data_df: pandas.DataFrame containing the data to add metadata information to. \n",
    "        metadata_df: pandas.DataFrame containing metadata information. \n",
    "        key_columns: list of str column names to use as keys for matching (e.g. ['subject_id', 'channel']\n",
    "        additional_columns: list of str column names from metadata_df to add to data_df. \n",
    "        \n",
    "    Returns:\n",
    "        merged_df: Updated DataFrame with original data_df and merged columns from metadata_df \n",
    "\n",
    "    \"\"\"\n",
    "    # Converts data within key columns to str \n",
    "    for key in key_columns:\n",
    "        data_df[key] = data_df[key].astype(str)  # Convert to string\n",
    "        metadata_df[key] = metadata_df[key].astype(str)  # Convert to string\n",
    "\n",
    "    # Filter metadata_df based on key_columns to match and additional_columns \n",
    "    metadata_subset = metadata_df[key_columns + additional_columns]\n",
    "    \n",
    "    # Merge data_df and metadata_df based on key columns \n",
    "    merged_df = data_df.merge(metadata_subset, on=key_columns, how='left')\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c60bcf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Example use case: \n",
    "\n",
    "# # get list of subject_ids that fit a few criteria referencing the metadata_df \n",
    "id_list = metadata_df[(metadata_df.qc_tissue == \"Pass\") & \n",
    "                     (metadata_df.qc_channel == \"Pass\") & \n",
    "                     metadata_df.virus.str.contains(\"AAV\")].subject_id.unique().tolist()\n",
    "\n",
    "#run id_list through batch_process, running a few at first to save time \n",
    "[cell_locations_df, cell_counts_df] = batch_process(id_list[0:2])\n",
    "\n",
    "#attach metadata info \n",
    "\n",
    "#define key columns for cross-referencing between data_df and metadata_df \n",
    "key_columns = [\"subject_id\", \"channel\"] \n",
    "\n",
    "#define additional columns to add \n",
    "additional_columns = [\"virus\", \"inj_structure\"]\n",
    "\n",
    "#add metadata to cell_locations_df and cell_counts_df \n",
    "cell_locations_with_metadata = add_metadata_info(cell_locations_df, metadata_df, key_columns, additional_columns)\n",
    "cell_counts_with_metadata = add_metadata_info(cell_counts_df, metadata_df, key_columns, additional_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bce8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate connectivity matrix and plot heatmap of cell counts \n",
    "\n",
    "# thalamic subregions of interest \n",
    "roiList = [\"MD\", \"PT\", \"IAD\", \"PVT\", \"IMD\", \"CM\", \"PCN\", \"CL\"]\n",
    "\n",
    "# filter the df for cells within the roiList \n",
    "filtered_cell_counts_df = cell_counts_with_metadata[cell_counts_with_metadata[\"Acronym\"].isin(roiList)] \n",
    "\n",
    "\n",
    "conn_mat = filtered_cell_counts_df.pivot_table(index = \"inj_structure\", \n",
    "                                      columns = \"Acronym\", \n",
    "                                      values = \"Total\")\n",
    "\n",
    "plt.imshow(conn_mat, cmap=\"gray_r\")\n",
    "plt.colorbar(label=\"cell counts\")\n",
    "plt.xticks(ticks=range(len(conn_mat.columns)), labels=conn_mat.columns, rotation=90)\n",
    "plt.yticks(ticks=range(len(conn_mat.index)), labels=conn_mat.index)\n",
    "plt.title(\"Connectivity Matrix\")\n",
    "plt.xlabel(\"Brain Regions\")\n",
    "plt.ylabel(\"Injection Site\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d21cb",
   "metadata": {},
   "source": [
    " Questions to explore further: \n",
    "\n",
    "* Can you predict x metadata from y measurement? (e.g. predict injection coordinates from labelled structures) \n",
    "\n",
    "* Does the virus identity matter? Assess the variability in targeted expression across injection sites. \n",
    "\n",
    "* Is there spatial topography in the labelling? \n",
    "\n",
    "* Explore expression patterns beyond the thalamus. Some starting points: amygdala, other cortial areas, locus coeruleus. \n",
    "    \n",
    "* Apply data-driven parcellations to the spatial coordinates of detected cells such as NMF \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
